{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "356e5538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from typing import List, Tuple\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "def pred_and_return_results(\n",
    "    model: torch.nn.Module,\n",
    "    class_names: List[str],\n",
    "    image_path: str,\n",
    "    image_size: Tuple[int, int] = (224, 224),\n",
    "    transform: torchvision.transforms = None,\n",
    "    device: torch.device = device,\n",
    "):\n",
    "    \"\"\"Predicts on a target image with a target model and returns the results.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): A trained (or untrained) PyTorch model to predict on an image.\n",
    "        class_names (List[str]): A list of target classes to map predictions to.\n",
    "        image_path (str): Filepath to target image to predict on.\n",
    "        image_size (Tuple[int, int], optional): Size to transform target image to. Defaults to (224, 224).\n",
    "        transform (torchvision.transforms, optional): Transform to perform on image. Defaults to None which uses ImageNet normalization.\n",
    "        device (torch.device, optional): Target device to perform prediction on. Defaults to device.\n",
    "    \n",
    "    Returns:\n",
    "        dict: A dictionary containing prediction results including label and probability.\n",
    "    \"\"\"\n",
    "\n",
    "    # Open image\n",
    "    img = Image.open(image_path)\n",
    "\n",
    "    # Create transformation for image (if one doesn't exist)\n",
    "    if transform is not None:\n",
    "        image_transform = transform\n",
    "    else:\n",
    "        image_transform = transforms.Compose(\n",
    "            [\n",
    "                transforms.Resize(image_size),\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(\n",
    "                    mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    ### Predict on image ###\n",
    "\n",
    "    # Make sure the model is on the target device\n",
    "    model.to(device)\n",
    "\n",
    "    # Turn on model evaluation mode and inference mode\n",
    "    model.eval()\n",
    "    with torch.inference_mode():\n",
    "        # Transform and add an extra dimension to image (model requires samples in [batch_size, color_channels, height, width])\n",
    "        transformed_image = image_transform(img).unsqueeze(dim=0)\n",
    "\n",
    "        # Make a prediction on image with an extra dimension and send it to the target device\n",
    "        target_image_pred = model(transformed_image.to(device))\n",
    "\n",
    "    # Convert logits -> prediction probabilities (using torch.softmax() for multi-class classification)\n",
    "    target_image_pred_probs = torch.softmax(target_image_pred, dim=1)\n",
    "\n",
    "    # Convert prediction probabilities -> prediction labels\n",
    "    target_image_pred_label = torch.argmax(target_image_pred_probs, dim=1)\n",
    "\n",
    "    # Prepare the result as a dictionary\n",
    "    result = {\n",
    "        \"label\": class_names[target_image_pred_label],\n",
    "        \"probability\": target_image_pred_probs.max().item()\n",
    "    }\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318786af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
